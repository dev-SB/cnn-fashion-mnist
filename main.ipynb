{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* loading mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split data in train images, labels and test images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use 60000 training images, scaled down to 28*28 pixels and grayscale (represented by 1 in reshape)\n",
    "* Normalize the images for value between 0,1 by dividing by 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img_train.reshape(60000, 28, 28, 1)\n",
    "img_train = img_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = img_test.reshape(10000, 28, 28, 1)\n",
    "img_test = img_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creation of the model:\n",
    "    * sequential defines that more layers can be added in sequence\n",
    "    * keras api to create neural network\n",
    "    * dense defines a layer of connected neurons, 1 dense = 1 layer\n",
    "    * its defines number of neurons in the layer\n",
    "    * input_shape defines the shape of input fed to the layer\n",
    "    * 3,3 convolutional layer and 2,2 max pooling layer are being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Conv2D(\n",
    "            64, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "        ),\n",
    "        keras.layers.MaxPooling2D(2, 2),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(2, 2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compile the model\n",
    "    * sparse_categorical_crossentropy: is the loss function that determines the error in each epoch\n",
    "    * adam: optimizing function that optimizes the model for next epoch\n",
    "    * accuracy: parameter being used to measure the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summary of the model:\n",
    "    * First layer outputs 26,26 images as we are using a 3,3 convolutional layer leading to loss of 2 rows and 2 columns. From 28*28 to 26*26\n",
    "    * 2,2 max pooling layer make the number of pixels half.\n",
    "    * flatten =5x5x64=1600 nodes, flatens the layer to be fed to a feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trainging our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 48s 805us/sample - loss: 0.4358 - accuracy: 0.8413\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 46s 772us/sample - loss: 0.2895 - accuracy: 0.8944\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 46s 762us/sample - loss: 0.2438 - accuracy: 0.9104\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 45s 751us/sample - loss: 0.2131 - accuracy: 0.9210\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 48s 796us/sample - loss: 0.1867 - accuracy: 0.9298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcad4413f50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_train,label_train,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluating model performance: accuracy 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 238us/sample - loss: 0.2636 - accuracy: 0.9095\n"
     ]
    }
   ],
   "source": [
    "loss=model.evaluate(img_test,label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualise the convolution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get labels of first 50 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5,\n",
       "       7, 9, 1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7,\n",
       "       6, 7, 2, 1, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can see that the images at index 2, index 5 and index 15 are all the same value: 1. We will take a look at the result of running the convolution on each, and as we begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between images based on this convolution/pooling combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD7CAYAAAC2a1UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de/AcZb3n8fcnV+R2JFxjiAaOrGu0RC6Lcji6QQ6KioZVQXC1Urts4bUKVqs0uqWe1aNGPGtJHS+QlRRxuSsiKRcvOVGMrmzMhVsgSgAjBLKJoEAEBBK++8f078dkfj2/6Znpnu6e+byqUr+ZZ3qmv/PNzPP0PP308ygiMDOzaplSdgBmZjaRK2czswpy5WxmVkGunM3MKsiVs5lZBblyNjOroL4qZ0mnSfqdpHskLc4rKDOzUddz5SxpKvAN4M3AfOAcSfPzCszc+JmNsml9PPcE4J6IuA9A0tXAQuCudk+QVNsrXo592V4AbPjdX/t5mYcj4uAsGzY1fqcCW4G1klZERGp+65bbsXw2G1RuodHwARcBU4FvR8SSDtt3ld8j9jpwQtmMabtSt33oiemp5Tvj4dTyGVP+JrX8meceyxhd9yJCRb12L5/d4447ouv93L1hZ1fbz9nnma738du/PN71c2jz2e2ncp4DPNB0fyvwms5Pm9rHLstz87KXAjDzpE19vMruP3SxcdeNX51yO5bPZoPKbbcN3/Oy5/cLLz19QtmLX/jn1G0/vX52avnPn/p2avnhL3hdavl9T/woY3Td2l3Q6zbr7rO7Zu3nu97Dqfv8sqvtlxz3QOeNWrzmFz/p+jntPrv9VM5pLemEFlDSecB5feynEv7L296Q3OqnAulKj42fZdBDw2c2WP2cENwKzG26fzjwUOtGEbE0Io6PiOP72Nco6tj4STpP0jpJ6wYU07BIa/jmtG7k/PbG50ry0U/lvBY4StIRkmYAZwMr8gnLyND4ueHrWaZffc5v9zxQID89d2tExC5JHwF+QqPDaFlE3JlbZBVz5aOXD3qX440f8CCNxu89gw6iKHu/bsKPrEHK9KvPeuIuo5z00+dMRNwI3JhTLNZk1Bq/ASu84dv46P4Tys66/dTUbdft/U+p5XvPnJdaftXxz6WWv+YX2WIrmM+V5KSvynmU7C5wmFI7bvyK4YavUCM1UKBIrpxtJLnhK0zmgQLAUqjfGP1B8dwaZpYnDxTIiY+crRRldBNZ8dxllB9XzmaWK3cZ5cOVs1kBDtrr2Qllf316e+q23/43J6SWv/v2K1LLI/5t74FZbbhyNrPaadfQTeYDRz3V1fYFzvWUiU8ImplVkCtnM7MKcuVsZlZB7nM2K8D0lOsq9KUvpW777tvT53lu5/v3HtlTTFYvPnI2M6sgV85mZhXkbg3ry67nlu9xf9qURSVFYjZcfORsZlZBI1E573pu+YQjPDOzKuvYrSFpGXA6sCMiXpmUzQKuAeYBW4CzIqK7U85mQyxtOvwLvtVuPv9vdPXaFz74za7jsfrJcuR8GXBaS9liYFVEHAWsSu5bziRtkXSHpFu9yKjZaOl45BwRqyXNayleCCxIbi8HbgI+kWNcubr+1T8pO4R+nBwRD5cdRDs1z61ZZfU6WuPQiNgGEBHbJB3SbkMvR2Nmebv0VXd3/ZzzN6fP8ldVhQ+lq8JyNGfefmUZu81DAD9N8nZJkstxbvjMhlevlfN2SbOTo+bZwI48g7JxJ0XEQ8kvk5WSfhsRq8cerELDZ2bF6LVyXgEsApYkf2/ILSIbFxEPJX93SLoeOAFYPfmzLAtJW4CdwG5gV0QcX/Q+f/eXvxa9i9JJmgt8BziMxqCVpRFxUblR1VOWoXRX0Tj5d5CkrcBnaVTK10o6F7gfOLPIIEeRpH2AKRGxM7n9RuBzJYc1QY27jKDiJ1trahfwsYjYIGk/YL2klRFxV9mB1U2W0RrntHnolJxjsT0dClwvCRr/T1dGxI/LDclscslAgbHBAjslbQLmAK6cu+S5NSoqIu4Dji47jiE26clW8AnXfiVDcI8B1qQ85tx24MrZRtWkJ1vBJ1z7IWlf4Drggoh4vPVx57azkZhbw6xV88lWYOxkq+VA0nQaFfMVEfH9suOpKx8528gZxMnWQ/aaODJj9VOX57mLSlLjJMmlwKaI+GrZ8dSZK2cbRT7ZWpyTgPcBd0i6NSn7VETcWGJMteTK2UaOT7YWJyJ+BajsOIaBK2czq51XH7y9+ydtzj+OIo1E5fyBQz4MwMU7ups31zr7zIs/uMf9z93/rZIiMRsuHq1hZlZBI3HkbDZoL9rvsbJDsJobicr5kL3SFg0yM6sud2uYmVXQSBw5+yRVcZxbs2L4yNnMrIJcOZuZVVDHylnSXEk/l7RJ0p2Szk/KZ0laKWlz8veA4sM1q4end02f8M+sG1mOnMdWNng58Frgw5LmA4uBVRFxFLAquW9mZjnIshJKu5UNFtJYvgpgOXAT8IlCoszJ5+d9AIBPb7m45EieJ2kZcDqwIyJemZTNAq4B5gFbgLMi4s9lxTiZ77/67D3uv+PWq0uKxGy4dNXn3LKywaFJxT1WgR+Sd3Aj4jLgtJYy/yoxG3GZh9K1rmyQTLeY5XlejmYSEbE6afSa1e5XidkgvejgHWWHULhMlXOblQ22S5odEdskzQZSs1Wl5Whe8cJHy9x9N/b4VZIspTSBG77qOmL2g2WHYDWXZbRGu5UNVgCLktuLgBvyD88mExFLI+L4iDi+7FjMLF9ZjpxTVzYAlgDXSjoXuB84s5gQ8/O2L/2icePN5caRQaZfJVUwntMx1c+tWS1kGa0x2coGp+QbjiXGfpUswb9KrIYkTQXWAQ9GxOllx1NHvkKwZJKuAm4GXiZpa/JLZAlwqqTNwKnJfbM6OR/YVHYQdTYSEx+NuWHxguTWVWWGsYeIOKfNQ/5VYrUk6XDgrcAXgI+WHE5tjVTlbKOlzAt8Vv32FSmla/LeTVV9Dfg4sF+7DTzSqLORqpzfdVvvR8wzph0GwDO7/l9e4QyF6W/e1tPzxvLZrIDcXgZ8HfhOU9nYBT5LJC1O7nsMeU4kjTWG6yUtaLddlYbYVpX7nG1oRcRq4E8txQtpXNhD8veMgQY1/E4C3i5pC3A18AZJl5cbUj25crZRk3naAUnnSVonad3Aoqu5iPhkRBweEfOAs4GfRcR7Sw6rlkaqW6Mf7s4YPf7pbWXykbONmu3JhT1U/QKfuouImzzGuXeKGNwBgaQ/Ak8ADw9sp8U4iN7ew0si4uC8g4Hx3P4hudtrfFXS7XtIzW0yqdQPm0ZrfAV4pOmE4KyI+HinF2/K7zDkNqux91rY5xYmfHbT9l+WQe0//bM7yMoZQNK6us8FUfX3UPX4ssjjPSQX+Cyg8SXbDnwW+AFwLfBikmkHIqL1pGGhcdVF2e911PfvPmcbWr7Ax+rMfc5mZhVURuW8tIR95q3q76Hq8WVR1fdQ1biKUPZ7Hen9D7zP2czMOnO3hplZBblyNjOroIFWzpJOk/Q7SfckY0wrT9JcST+XtEnSnZLOT8pnSVopaXPy94AKxFq7/EJj9jhJOyRtbCpzfgek7Px3yqukmZKuSR5fk7Igcj/7Tv1+t2yzQNJjkm5N/n0mr/1PKiIG8g+YCtwLHAnMAG4D5g9q/33EPRs4Nrm9H3A3MB+4EFiclC8GvlxynLXMbxL764FjgY1NZc7vCOQ/S16BDwEXJ7fPBq7Jcf+p3++WbRbQuJBpoP8vgzxyPgG4JyLui4hnaMxYtXCA++9JRGyLiA3J7Z00VneYQ/VmN6tlfqE2s8fVNr+dlJz/LHltjuV7wCnJwtN9m+T7Xbq+Kucuf+bNAR5our+ViiQhq+Tn1DE0Zk3PPLvZgNQ+vy2c33INKv9Z8jq+TUTsAh4DDsw7kJbvd6sTJd0m6UeS0lZSyF3PlXOygOM3aKy3PB84R9L8yZ6SUlabcXyS9gWuAy6IiMcHtM9uGr9a57cGnN9iZMlr4bnv8P3eQGP+i6OBf6ExBUDheh7nLOlE4B8j4k3J/U8CRMSXJtn+1z3GOSwejowTyCSN3900FnjdCqwFzomIu9psX/uKYopmTih7Lp7O+vTMuYVGwwdcRKPP89sRMekiut3m97DpEw8057xqn9Rt16//fZtXaXfs1O4X/e6OcfXh7oh4Wd4v2mu9cNxxR3S9rztueaSr7ffTXl3v45HdPU1ymPrZ7WdujbSfI69p3WjiWmFT+9hl3e1Om3mrnfG+OABJY31xqZVzQ71z+4IZL5lQ9sTT92Z8dvbcNv3qG2/4JK1o1/A9L3t+//Oh755Q9rm1E74eAEybsqhNnOmVgzQ9tfy553ZmjK5buwFuKOjF1zb+dPfZXbP2813v6KX7X9nV9v9+xku73sfyP32j6+e0++z20+ec6adGRCyNiONjSGby2mfm347/K9io9XEO0tCe3CvQpL8sepX0IVuKfirnrcDcpvuHAw/1F4416dj4eRmlnmVq+Jzf50V306oO5XjwQeuncl4LHCXpCEkzaIw/XJFPWEaGxm/YfpUM0Ej+6huEHgYKWBs99zlHxC5JHwF+QqPDaFlE3JlbZBX1w2OfH0Vz8s1Z+0N7Mt74AQ/SaPzeU+QOy9ac2zEF5di/+orTw7kSS9PXZPsRcSNwY06xWJNRbfwGpPCG779/67sTyu47Y0PqtgfufUxq+X5T0ocWtztR1dvJqNz1OFDAWnkllC7969bBnZNz41cMN3yFytxlhFc2n5QrZxtJbvgK4y6jnHjKUDPLkwcK5MRHzl36wgPfKjuEoXXyzf4O1527jPLjytnMcuUuo3y4cjYrwDNrJs5z8c83H5e67a1v/1Vq+Wkr9k0tbzcq46cnvCO1/I2/+X5quVWbK2czK5U0nRnTDuvqOU9/5r92vZ9fnj6380ZNNt2XPlHVZJb/puuntOUTgmZmFeTK2cysglw5m5lVkPuczfowc/qLUsu/8r/ePqHs5MMeS932736YvuLSA09e11UsZ9yWfnm41ZOPnM3MKsiVs5lZBblbw/ry7KV7Li80/dxC17EzGxk+cjYzq6CRqJyfvXTqhCM8M7Mq69itIWkZcDqwIyJemZTNAq4B5gFbgLMi4s/FhWlWTYfNTF+B6fKHH5hQdlmbC9Qe+MvPconlyae35PI6Vg1ZjpwvA05rKVsMrIqIo4BVyX3LmaQtku6QdKsXGTUbLR2PnCNitaR5LcULgQXJ7eXATcAncowrV/pPyxo3zl1UbiC9OTkiHi47iHbGczumnjk2q5xeR2scGhHbACJim6T0xc7wWmFmNrm92Z9XTTu1q+fcclP3xyt//6v/3eUzbut6H3kqfChdFdYKmzaltkdzAfw0ydslSS7HueEzG169Vs7bJc1OjppnAzvyDMrGnRQRDyW/TFZK+m1ErB57sAoNn5kVo9fKeQWwCFiS/L0ht4hsXEQ8lPzdIel64ARg9eTPsiwkbQF2AruBXRFxfC+v86Ld6aux37J71YSy/3nXwl52USuS5gLfAQ4DngOWRsRF5UZVT1mG0l1F4+TfQZK2Ap+lUSlfK+lc4H7gzCKD7MUFsz88fvtr29JXjqgySfsAUyJiZ3L7jcDnyozpmYsmflxq3GUEFT/ZWlO7gI9FxAZJ+wHrJa2MiLvKDqxusozWOKfNQ6fkHIvt6VDgeknQ+H+6MiJ+XG5IZpNLBgqMDRbYKWkTMAdw5dyloZ1b48LFl4zf/tr5JQbSo4i4Dzi67DiG2KQnW8EnXPuVDME9BliT8th4bmeo++WgRsHQVs5mHUx6shV8wrUfkvYFrgMuiIjHWx9vzu2+Uw5yblMMbeU84/xdZYcwdIYppz7ZWhxJ02lUzFdEhJf+7tHQVs5m7eR5snUT61PL//rM1glly/9UvxPT3VLjJMmlwKaI+GrZ8dSZK2cbRT7ZWpyTgPcBd0i6NSn7VETcWGJMteTK2UaOT7YWJyJ+BajsOIaBK2czK9VfebJt91A7X9/4+oKied7n532g6+d8esvFue1/JCrnZ6/eG4DpZz9ZciTDZyy3Y5xjs3yMxEooZmZ1MxJHzmZFefSpjanlZ7/wQxPKrn70m7nss93P7Tx/Ulv5RqJyfmbjXskt/+Q2s3pwt4aZWQWNxJHzPv/0p7JDGFo+AWhWDB85m5lVkCtnM7MKyjLZfurKBpJmAdcA84AtwFkR8efiQjWrj/e/fOLcGlffnNNr/8PEVVYAPv3tfF7fqiHLkfPYygYvB14LfFjSfGAxsCoijgJWJfetS5KWSdohaWNT2SxJKyVtTv4eUGaMZjZ4HSvniNgWERuS2zuBsZUNFgLLk82WA2cUFWRevnjE+/niEe8vO4xWlwGntZTVpuHbctYxe/wzs3x01efcsrLBocmSNGNL0xySd3CjIJngvXU4Se0aPjPLV+ahdK0rGyTTLWZ5npf66d4eDV+yWofZUNodT7W90rKd97/6yK73022ff7u+/cnk2e+fqXJus7LBdkmzk8pjNrAj7blVWurnPf/uNwB86vdlRpEfN3zVtfHh4trT/3jlyW0e2VzYPm3wOnZrTLKywQpgUXJ7EXBD/uGNrO1Jg0enhi8ijo+I4wcanZkVLsuRc+rKBsAS4FpJ5wL3A2cWE2J+fv/A3OTWLaXGkcFYw7eEijd8z+e0Yeb07RO2efrZhwYVjlWEpKnAOuDBiDi97HjqqGPl3GFlg1PyDWf0SLoKWAAcJGkr8Flq2PCZtTifxsiu/csOpK5GYm6NKouIc9o85IbPaknS4cBbgS8AHy05nNoaqcr55JtXADBz+ovGy/yT2yx3XwM+DuxXdiB1NlKVs40WScuA04EdEfHKpGwg0w78nz/OyPslx618cmlq+T4z/za1/Imn7y0sllaSxvK9XtKCSbbzSKMORrJy/vXr5o/fPu5nPnLux9ivkTHr3/APE7YpMceXAV+nMTfMmLGrL5dIWpzc/0QJsQ2rk4C3S3oLsBewv6TLI+K9zRtVaYhtVXlWOhtavvpy8CLikxFxeETMA84GftZaMVs2I3nkbCMt89WX/ultZRrJyvnE1d1dKmqjyT+9+xMRNwE3lRxGbblbw0ZNpqsvzcqmiMEdEEj6I/AE8PDAdlqMg+jtPbwkIg7OOxgYz+0fkru9xlcl3b6H1NwmMyn+sGm0xleAR5pOCM6KiI93evGm/A5DbrMae6+FfW5hwmc3bf9lGdT+0z+7g6ycASStq/tcEFV/D1WPL4s83kPz1ZfAdhpXX/4AuBZ4McnVlxGReQXgYchtVmW/11Hf/0j2Odto8NWXVmfuczYzq6AyKuf0y5vqpervoerxZVHV91DVuIpQ9nsd6f0PvM/ZzMw6c7eGmVkFuXI2M6uggVbOkk6T9DtJ9yRjTCtP0lxJP5e0SdKdks5PymdJWilpc/L3gArEWrv8QmP2OEk7JG1sKnN+B6Ts/HfKq6SZkq5JHl+TjF3Pa9+p3++WbRZIekzSrcm/z+S1/0lFxED+AVOBe4EjgRnAbcD8Qe2/j7hnA8cmt/cD7gbmAxcCi5PyxcCXS46zlvlNYn89cCywsanM+R2B/GfJK/Ah4OLk9tnANTnuP/X73bLNAhoXMg30/2WQR84nAPdExH0R8QxwNY0ZwiotIrZFxIbk9k4aS+/MoXqzm9Uyv1Cb2eNqm99OSs5/lrw2x/I94JRk4em+TfL9Ll1flXOXP/PmAA803d9KRZKQVfJz6hhgDS2zmwFtZzcbkNrnt4XzW65B5T9LXse3iYhdwGPAgXkH0vL9bnWipNsk/UjSK/Led5qeK+dkdd1vAG+m8TP/HEnzJ3tKSlltxvFJ2he4DrggIh4f0D67afxqnd9B66H/2PktRpa8Fp77Dt/vDTTmvzga+BcaUwAUrudxzpJOBP4xIt6U3P8kQER8aZLtf91jnOOmT9l3/Pazz/2l35fL7LjjjgBg/frf9/MyD0fGCWSSxu9u4FQaRxNrgXMi4q422/f8YW3O6ZiiczuWz2ZVzW3ynBwqg3azJezq/6WLd3dEvCzvF+21XnjZPi/sel93P/lkV9s3elkGIvWz28/cGmk/R17TutHECcun9rFLOPgFz89D8tATv+zrtbqxZu3nAZg2ZVEfr7I7beatdsb74gAkjfXFta1Aes1tc07HFJ3bsXw2q3Zuod/P7rSps1LLd+1+pK/XLd5ugBsKevG1jT/d5Xbp0Qu63tFp627ravunnrm/6330Jv2z20/lnOmnRuQ8YfkgK+Rm/VUcPenY+Hmljp5lOrCwPSwp4kUjYldO5/aGTj8nBLcCc5vuHw54tdT8dGz8ImJpRBwfIzKFZY4yHVhIOk/SOknrBhBTpUV306oO5XjwQeuncl4LHCXpCEkzaIw/XNHhOZadG7/iZMqtG7/u9TBQwNrouVsj+TnyEeAnNDqMlkXEnblFZuONH/AgjcbvPUXsqIyuohK6iZoNLLcjqMf+fGvV12T7EXEjcGNOsVgTN37FGURuX7H3OyeU/Y82o2PPuC1tWC389ZmteYY0KD0OFLBWXgmlwtz4Fce5LUwpAwWGkWelM7M8+VxJTlw5m1mePFAgJ+7WMLPc+FxJflw5m1mu3J+fD1fOZgWYP/3QCWWf2vho6ravm/aW1PLL3/uL1PKb1qUPu3737VdkjM7qwJWzmdXOJZvmdt6oxbYP3tLV9r9Y/e6u97Hwlmu6fk47PiFoZlZBrpzNzCrIlbOZWQW5z9msAN997JuZt73vnekn+CLSp9L0ib/R4CNnM7MKcuVsZlZBrpzNzCrIlbOZWQV1rJwlLZO0Q9LGprJZklZK2pz8PaDYMM3MRkuW0RqXAV8HvtNUthhYFRFLkjXCFgOfyD88s+Hxzv0/lFp+4Et+kFo+44CdRYZjFdfxyDkiVgOtizsuBJYnt5cDZ+QclwGStki6Q9KtXmTUbLT0Os750IjYBhAR2yQdkmNMtqeTI+LhsoMws8Eq/CIUrxVmZnmbqvQLdCaz90u3dbX9wovym8SoF72O1tguaTZA8ndHuw29vHxfAvippPVJI7cHSedJWucuD7Ph02vlvAIYW9t+EXBDPuFYi5Mi4ljgzcCHJb2++UE3fL1zf34xJM2V9HNJmyTdKen8smOqq47dGpKuAhYAB0naCnwWWAJcK+lc4H7gzCKDHFUR8VDyd4ek64ETgNXlRjVUCuvPf8f+H5xQNr3NoVC7URlv+uJZbV790h6jGohdwMciYoOk/YD1klZGxF1lB1Y3HSvniDinzUOn5ByLNZG0DzAlInYmt98IfK7ksMwmlQwUGBsssFPSJmAO4Mq5S56VrroOBa5X48THNODKiPhxuSENlbH+/AAuiYilZQc0bCTNA44B1pQbST25cq6oiLgPOLrsOIbYSRHxUDIMdKWk3yZj+sd5pFHvJO0LXAdcEBGPpzzu3HbguTVsJDX35wNj/fmt2/iEaw8kTadRMV8REd9P28a57cyVs40cSfskJ6to6s/fOPmzLAs1+uEuBTZFxFfLjqfO3K1ho6jw/vxD9pp43POzJ+5P3fY7V7wrtXz1U5UeldHOScD7gDsk3ZqUfSoibiwxplpy5Wwjx/35xYmIXwHdX75nE7hbw8ysgnzkbGa188IZ3T9n5WX/octnfK/7neTIR85mZhXkytnMrILcrWFWgEt2XDKh7D0HvD912wNntq5lYeYjZzOzSnLlbGZWQa6czcwqyJWzmVkFuXI2M6ugLCuhzAW+AxwGPAcsjYiLJM0CrgHmAVuAsyLiz8WFalYfU6fuN6Hsj08/m7rtm97yr+kvclueEVndZDlyHlt25uXAa2msZTcfWAysioijgFXJfeuSpGWSdkja2FQ2S9JKSZuTvweUGaOZDV7HyjkitkXEhuT2TmBs2ZmFwPJks+XAGUUFOeQuA05rKXPDZzbiuupzbll25tBkvbCxdcMOafOc8ySt8wrH6ZLVN1qvQnDDZzbiMl8h2LrsTDIXbkfJ2mxLk9eIXoIcQXs0fMlSSmaWuHfnrq6f86a1b+vuCVPKnfgoU+XcZtmZ7ZJmJ5XHbGBHUUFaOq/DVl2vnTFxBrSfPpm+huxzn/h4+ot86cI8Q7Ka6ditMcmyMyuARcntRcAN+Yc3srYnDR6TNXxeh81seGXpcx5bduYNkm5N/r0FWAKcKmkzcGpy3/Lhhs9qTdJUSbdI+mHZsdRVx26NDsvOnJJvOKNH0lXAAuAgSVuBz9Jo6K6VdC5wP3BmeRGa9eR8GiO79i87kLrylKEli4hz2jzkhs9qSdLhwFuBLwAfLTmc2vLl22aWt68BH6dxRXEqD7HtzEfONrQkLQNOB3ZExCuTsoFMO/Cq/V8woexXT6Vvu8/+r8h796WRNJbv9ZIWtNvOQ2w785GzDbPL8NWXg3YS8HZJW4CraQwkuLzckOrJlbMNLV99OXgR8cmIODwi5gFnAz+LiPeWHFYtuVvDRk3mqy99kY+VyZWzWRvuF+1PRNwE3FRyGLXlbg0bNZmuvjQrmyIGd0Ag6Y/AE8DDA9tpMQ6it/fwkog4OO9gYDy3f0ju9hpflXT7HlJzm8yk+MOm0RpfAR6JiCWSFgOzIqLN5BZ7vM5Yfocht1mNvdfCPrcw4bObtv+yDGr/6Z/dQVbOAJLW1X0uiKq/h6rHl0Ue76H56ktgO42rL38AXAu8mOTqy4hoPWlYaFx1UfZ7HfX9u8/ZhpavvrQ6c5+zmVkFlVE5p09qWy9Vfw9Vjy+Lqr6HqsZVhLLf60jvf+B9zmZm1pm7NczMKmiglbOk0yT9TtI9yTCmypM0V9LPJW2SdKek85PyWZJWStqc/D2gArHWLr/QmKBI0g5JG5vKnN8BKTv/nfIqaaaka5LH1yTDI/Pad+r3u2WbBZIea1ps5DN57X9SETGQf8BU4F7gSGAGcBswf1D77yPu2cCxye39gLuB+cCFwOKkfDHw5ZLjrGV+k9hfDxwLbGwqc35HIP9Z8gp8CLg4uX02cE2O+0/9frdss4DGWPmB/r8M8sj5BOCeiLgvIp6hMWPVwgHuvycRsS0iNiS3d9JY3WEO1ZtAp5b5hdpMUFTb/HZScv6z5LU5lu8BpyRrm/Ztku936QZZOc8BHmi6vzLVMw4AAAG1SURBVJWKJCGr5OfUMcAaWibQAdpOoDMgtc9vC+e3XIPKf5a8jm8TEbuAx4AD8w6k5fvd6kRJt0n6kaSBTMA9yItQ0lq62gwVkbQvcB1wQUQ8nlPDnada57cGnN9iZMlr4blv/X63PLyBxiXWf0kWt/4BcFSe+08zyCPnrcDcpvuHAw8NcP89kzSdxn/cFRHx/aS4ahPo1Da/bTi/5RpU/rPkdXwbSdOAv2FiN0zP2ny/x0XE4xHxl+T2jcB0SQfltf92Blk5rwWOknSEpBk0OvZXDHD/PUn6ti4FNkXEV5seWgEsSm4vAm4YdGwtapnfSTi/5RpU/rPktTmWd9GYwD+XI+dJvt/N2xw21sct6QQa9eYjeex/UoM8+wi8hcbZ0HuB/zbos589xvz3NH5C3Q7cmvx7C40+r1XA5uTvrArEWrv8JnFfBWwDnqVxlHSu8zs6+U/LK/A54O3J7b2A7wL3AL8Bjsxx3+2+3x8APpBs8xHgThojSf4v8HeD+H/xFYJmZhXkKwTNzCrIlbOZWQW5cjYzqyBXzmZmFeTK2cysglw5m5lVkCtnM7MKcuVsZlZB/x9WNpMXS1iiUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(3,4)\n",
    "first_image=2\n",
    "scnd_image=5\n",
    "thrd_image=15\n",
    "conv_no = 1\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(img_test[first_image].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, conv_no], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(img_test[scnd_image].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, conv_no], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(img_test[thrd_image].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, conv_no], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
